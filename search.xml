<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>CIFAR10_Original_ver</title>
    <url>/2022/07/06/CIFAR10-Original-ver/</url>
    <content><![CDATA[<h3 id="这是最早的一个版本，比较简陋。后续会再整理有关于参考ResNet-VGG网络来实现的过程"><a href="#这是最早的一个版本，比较简陋。后续会再整理有关于参考ResNet-VGG网络来实现的过程" class="headerlink" title="这是最早的一个版本，比较简陋。后续会再整理有关于参考ResNet,VGG网络来实现的过程"></a>这是最早的一个版本，比较简陋。后续会再整理有关于参考ResNet,VGG网络来实现的过程</h3><h3 id="Step-1-Orginial-Code"><a href="#Step-1-Orginial-Code" class="headerlink" title="Step 1. Orginial Code"></a>Step 1. Orginial Code</h3><h4 id="1-1-import"><a href="#1-1-import" class="headerlink" title="1.1 import"></a>1.1 import</h4><figure class="highlight elm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="title">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br></pre></td></tr></table></figure>
<h4 id="1-2-Data-processing"><a href="#1-2-Data-processing" class="headerlink" title="1.2 Data processing"></a>1.2 Data processing</h4><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">transform_train = transforms.Compose([</span><br><span class="line">    transforms.RandomCrop(32,<span class="attribute">padding</span>=4),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))</span><br><span class="line">])</span><br><span class="line">transform_test = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))</span><br><span class="line">])</span><br><span class="line">trainset = torchvision.datasets.CIFAR10(<span class="string">&#x27;./cifar-10-batches-py/&#x27;</span>,<span class="attribute">train</span>=<span class="literal">True</span>, <span class="attribute">download</span>=<span class="literal">True</span>,</span><br><span class="line">                                       transform = transform_train)</span><br><span class="line">trainloader = DataLoader(trainset,<span class="attribute">batch_size</span>=64,shuffle=True,num_workers=2)</span><br><span class="line"></span><br><span class="line">testset = torchvision.datasets.CIFAR10(<span class="string">&#x27;./cifar-10-batches-py/&#x27;</span>,<span class="attribute">train</span>=<span class="literal">False</span>, <span class="attribute">download</span>=<span class="literal">True</span>,</span><br><span class="line">                                       transform = transform_test)</span><br><span class="line">testloader = DataLoader(testset,<span class="attribute">batch_size</span>=64,shuffle=True,num_workers=2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="1-3-Create-Net"><a href="#1-3-Create-Net" class="headerlink" title="1.3 Create Net"></a>1.3 Create Net</h4><figure class="highlight css"><table><tr><td class="code"><pre><span class="line">class Net(nn<span class="selector-class">.Module</span>):</span><br><span class="line">    def <span class="built_in">__init__</span>(self):</span><br><span class="line">        <span class="built_in">super</span>(Net,self).<span class="built_in">__init__</span>()</span><br><span class="line">        self.conv1 = nn.<span class="built_in">Sequential</span>(</span><br><span class="line">            nn.<span class="built_in">Conv2d</span>(<span class="number">3</span>,<span class="number">16</span>,<span class="number">3</span>,padding=<span class="number">1</span>), # <span class="number">3</span>*<span class="number">32</span>*<span class="number">32</span> &gt;&gt;<span class="number">16</span>*<span class="number">32</span>*<span class="number">32</span></span><br><span class="line">            nn.<span class="built_in">ReLU</span>(),</span><br><span class="line">        )</span><br><span class="line">        self.conv2 = nn.<span class="built_in">Sequential</span>(</span><br><span class="line">            nn.<span class="built_in">Conv2d</span>(<span class="number">16</span>,<span class="number">32</span>,<span class="number">3</span>,padding=<span class="number">1</span>),</span><br><span class="line">            nn.<span class="built_in">ReLU</span>(),</span><br><span class="line">            nn.<span class="built_in">MaxPool2d</span>(<span class="number">2</span>,<span class="number">2</span>)# <span class="number">32</span>*<span class="number">32</span>*<span class="number">32</span> &gt;&gt;<span class="number">32</span>*<span class="number">16</span>*<span class="number">16</span></span><br><span class="line">        )</span><br><span class="line">        self.conv3 = nn.<span class="built_in">Sequential</span>(</span><br><span class="line">            nn.<span class="built_in">Conv2d</span>(<span class="number">32</span>,<span class="number">64</span>,<span class="number">3</span>,padding=<span class="number">1</span>),# <span class="number">64</span>*<span class="number">16</span>*<span class="number">16</span></span><br><span class="line">            nn.<span class="built_in">ReLU</span>(),</span><br><span class="line">        )</span><br><span class="line">        self.conv4 = nn.<span class="built_in">Sequential</span>(</span><br><span class="line">            nn.<span class="built_in">Conv2d</span>(<span class="number">64</span>,<span class="number">128</span>,<span class="number">3</span>,padding=<span class="number">1</span>),<span class="number">#128</span>*<span class="number">16</span>*<span class="number">16</span></span><br><span class="line">            nn.<span class="built_in">ReLU</span>(),</span><br><span class="line">            nn.<span class="built_in">MaxPool2d</span>(<span class="number">2</span>,<span class="number">2</span>)<span class="number">#128</span>*<span class="number">8</span>*<span class="number">8</span></span><br><span class="line">        )</span><br><span class="line">        self.conv5 = nn.<span class="built_in">Sequential</span>(</span><br><span class="line">            nn.<span class="built_in">Conv2d</span>(<span class="number">128</span>,<span class="number">256</span>,<span class="number">3</span>,padding=<span class="number">1</span>),<span class="number">#256</span>*<span class="number">8</span>*<span class="number">8</span></span><br><span class="line">            nn.<span class="built_in">ReLU</span>(),</span><br><span class="line">            nn.<span class="built_in">MaxPool2d</span>(<span class="number">2</span>,<span class="number">2</span>)<span class="number">#256</span>*<span class="number">8</span>*<span class="number">8</span> &gt;&gt; <span class="number">256</span>*<span class="number">4</span>*<span class="number">4</span></span><br><span class="line">        )</span><br><span class="line">        self.gap = nn.<span class="built_in">AvgPool2d</span>(<span class="number">4</span>,<span class="number">4</span>) <span class="number">#256</span>*<span class="number">1</span>*<span class="number">1</span></span><br><span class="line">        self.fc = nn.<span class="built_in">Linear</span>(<span class="number">256</span>,<span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    def <span class="built_in">forward</span>(self,x):</span><br><span class="line">        x = self.<span class="built_in">conv1</span>(x)</span><br><span class="line">        x = self.<span class="built_in">conv2</span>(x)</span><br><span class="line">        x = self.<span class="built_in">conv3</span>(x)</span><br><span class="line">        x = self.<span class="built_in">conv4</span>(x)</span><br><span class="line">        x = self.<span class="built_in">conv5</span>(x)</span><br><span class="line">        x = self.<span class="built_in">gap</span>(x)</span><br><span class="line">        x = x.<span class="built_in">view</span>(-<span class="number">1</span>, <span class="number">256</span>)</span><br><span class="line">        x = self.<span class="built_in">fc</span>(x)</span><br><span class="line">        return x</span><br><span class="line">    </span><br><span class="line">net = <span class="built_in">Net</span>()</span><br><span class="line"></span><br><span class="line">criterion = nn.<span class="built_in">CrossEntropyLoss</span>()</span><br><span class="line">optimizer = optim.<span class="built_in">Adam</span>(net.<span class="built_in">parameters</span>(),lr=<span class="number">0.005</span>)</span><br></pre></td></tr></table></figure>
<h4 id="1-4-Train-and-Test"><a href="#1-4-Train-and-Test" class="headerlink" title="1.4 Train and Test"></a>1.4 Train and Test</h4><figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">def train(epochs, <span class="attribute">log_interval</span>=50):</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">        running_loss = 0.0</span><br><span class="line">        <span class="keyword">for</span> <span class="keyword">step</span>, (batch_x,batch_y) <span class="keyword">in</span> enumerate(trainloader):</span><br><span class="line">            output = net(batch_x)</span><br><span class="line">            </span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss = criterion(output,batch_y)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.<span class="keyword">step</span>()</span><br><span class="line">            </span><br><span class="line">            running_loss += loss.item()</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">step</span>%log_interval == (log_interval-1):</span><br><span class="line">                running_loss = 0.0</span><br><span class="line"></span><br><span class="line">def test():</span><br><span class="line">    correct = 0</span><br><span class="line">    total = 0</span><br><span class="line">    with torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">            X, y = data</span><br><span class="line">            output = net(X)</span><br><span class="line">            _,predicted = torch.max(output.data, <span class="attribute">dim</span>=1)</span><br><span class="line">            total += y.size(0)</span><br><span class="line">            correct += (predicted == y).sum().item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set : %.3f %%&#x27;</span> % (100<span class="number">*c</span>orrect/total))</span><br><span class="line">    </span><br><span class="line">EPOCHS = 20</span><br><span class="line"></span><br><span class="line">train(<span class="attribute">epochs</span>=EPOCHS)</span><br><span class="line">test()</span><br><span class="line">```  </span><br><span class="line"><span class="comment">#### Result: Accuracy on test set : 73.160 %</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Step 2. Explanations</span></span><br><span class="line"><span class="comment">#### 2.1 In data processing  </span></span><br><span class="line">将transform 进一步分为transform_train, transform_test来提高准确度。  </span><br></pre></td></tr></table></figure>
<p>transforms.RandomCrop(32,padding&#x3D;4),<br>transforms.RandomHorizontalFlip(),</p>
<p>&#96;&#96;&#96;<br>Ref: <a href="https://blog.csdn.net/qq_36523492/article/details/107357532">transforms的二十二个方法</a><br>作用：起数据增强的作用，所以主要是对trainset进行变动，testset依旧是<code>.ToTensor(), .Normalize()</code>  </p>
<h4 id="2-2-In-Net"><a href="#2-2-In-Net" class="headerlink" title="2.2 In Net"></a>2.2 In Net</h4><p>用了<code>nn.Sequential()</code>来包含每一层的Conv2d,ReLU和MaxPool2d操作<br>Ref: <a href="https://blog.csdn.net/qq_27825451/article/details/90551513">nn.Sequential类详解——使用Sequential类来自定义顺序连接模型</a></p>
<h3 id="Step-3-Problems"><a href="#Step-3-Problems" class="headerlink" title="Step 3. Problems"></a>Step 3. Problems</h3><ol>
<li>准确度不够高</li>
<li>自己还没有研究怎么去看每一个类的准确度之类的(classes完全没有用上)</li>
<li>因为电脑配置问题暂时还不能使用GPU</li>
</ol>
]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>CN</tag>
        <tag>CIFAR</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo常见操作</title>
    <url>/2022/07/05/Hexo%E5%B8%B8%E8%A7%81%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<h3 id="1-文章发布"><a href="#1-文章发布" class="headerlink" title="1. 文章发布"></a>1. 文章发布</h3><h4 id="1-1-创建新文章"><a href="#1-1-创建新文章" class="headerlink" title="1.1 创建新文章"></a>1.1 创建新文章</h4><p><code>$ hexo new post &quot;A Quick Start for Blog Writing-Markdown&quot;	# 这里引号里面是博客名称 </code></p>
<h4 id="1-2-编辑文章"><a href="#1-2-编辑文章" class="headerlink" title="1.2 编辑文章"></a>1.2 编辑文章</h4><p>用Markdown编辑器编译<br>Markdown 相关资料：<br><a href="https://www.jianshu.com/p/c2814458dbfe">Markdown 公式指导手册</a><br><a href="https://markdown.com.cn/cheat-sheet.html#%E6%80%BB%E8%A7%88">Markdown官方教程总览</a></p>
<h4 id="1-3发布-x2F-更新文章"><a href="#1-3发布-x2F-更新文章" class="headerlink" title="1.3发布&#x2F;更新文章"></a>1.3发布&#x2F;更新文章</h4><figure class="highlight crystal"><table><tr><td class="code"><pre><span class="line"><span class="variable">$ </span>hexo clean</span><br><span class="line"><span class="variable">$ </span>hexo g</span><br><span class="line"><span class="variable">$ </span>hexo server	<span class="comment"># 先在本地预览一下，这一步也可以跳过，直接到下一步</span></span><br><span class="line"><span class="variable">$ </span>hexo d</span><br></pre></td></tr></table></figure>

<h3 id="2-Hexo主题配置"><a href="#2-Hexo主题配置" class="headerlink" title="2. Hexo主题配置"></a>2. Hexo主题配置</h3><h4 id="2-1-主题优化"><a href="#2-1-主题优化" class="headerlink" title="2.1 主题优化"></a>2.1 主题优化</h4><p><a href="https://blog.csdn.net/nightmare_dimple/article/details/86661502">Next主题美化</a><br><a href="http://theme-next.iissnan.com/">NextT 官网</a><br><a href="https://www.jianshu.com/p/1ff2fcbdd155">Hexo博客第三方主题next进阶教程</a><br><a href="https://blog.csdn.net/qq_36759224/article/details/82121420">使用 Github Pages 和 Hexo 搭建自己的独立博客【超级详细的小白教程】</a><br><a href="https://blog.csdn.net/qq_36759224/article/details/85420403">Hexo 博客优化之博客美化系列（持续更新）</a><br><a href="https://blog.csdn.net/qq_36759224/article/details/85010191">Hexo 博客优化之实用功能添加系列（持续更新）</a></p>
<h5 id="网站图像更换"><a href="#网站图像更换" class="headerlink" title="网站图像更换"></a>网站图像更换</h5><p><a href="https://www.bitbug.net/">在线制作ico图标</a><br><a href="https://thenounproject.com/icons/">icon search</a><br>然后选择或者创建相应大小的图标文件，放置在<code>blog/themes/next/sources/images</code>目录下，并在主题配置文件中进行如下配置，只需要设置small和medium两个就可以  </p>
<figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="symbol">favicon:</span></span><br><span class="line"><span class="symbol">  small:</span> <span class="keyword">/images/</span><span class="number">16</span>x16.png</span><br><span class="line"><span class="symbol">  medium:</span> <span class="keyword">/images/</span><span class="number">32</span>x32.png</span><br><span class="line"><span class="symbol">  apple_touch_icon:</span> <span class="keyword">/images/</span><span class="number">128</span>x128.png</span><br><span class="line"><span class="symbol">  safari_pinned_tab:</span> <span class="keyword">/images/</span>logo2.svg</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2-2-Git同步不同平台"><a href="#2-2-Git同步不同平台" class="headerlink" title="2.2 Git同步不同平台"></a>2.2 Git同步不同平台</h4><p><a href="https://blog.csdn.net/sinat_37781304/article/details/82729029">Hexo最全搭建教程</a>(见3. git分支进行多终端工作)<br><a href="https://www.zhihu.com/question/21193762">使用hexo，如果换了电脑怎么更新博客？</a><br>我的进度：目前已经按照教程弄完了，但没在其他电脑上尝试过</p>
<h4 id="2-3-Hexo添加页面（以分类和标签为例）"><a href="#2-3-Hexo添加页面（以分类和标签为例）" class="headerlink" title="2.3 Hexo添加页面（以分类和标签为例）"></a>2.3 Hexo添加页面（以分类和标签为例）</h4><p><a href="https://www.jianshu.com/p/7667d8e8f91c">hexo创建各种页面问题</a><br><a href="https://www.jianshu.com/p/e17711e44e00">Hexo使用攻略-添加分类及标签</a><br>记得打tags和categories时，-后面有空格</p>
<h3 id="3-未来想要尝试的"><a href="#3-未来想要尝试的" class="headerlink" title="3.未来想要尝试的"></a>3.未来想要尝试的</h3><ol>
<li>修饰页面边栏和底栏</li>
<li>添加字数和阅读时长</li>
<li>尝试插入图片</li>
<li>Markdown公式插入</li>
<li>添加搜索功能</li>
<li>修改网页小图标</li>
</ol>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>CN</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>MNIST_study</title>
    <url>/2022/07/05/MNIST-study/</url>
    <content><![CDATA[<h3 id="Main-Steps"><a href="#Main-Steps" class="headerlink" title="Main Steps"></a>Main Steps</h3><ol>
<li>导入数据，数据加载和预处理</li>
<li>定义神经网络</li>
<li>定义损失函数和优化器</li>
<li>训练和测试</li>
</ol>
<h3 id="Step-1-导入数据，数据加载和预处理"><a href="#Step-1-导入数据，数据加载和预处理" class="headerlink" title="Step 1.导入数据，数据加载和预处理"></a>Step 1.导入数据，数据加载和预处理</h3><figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms,datasets</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">batch_size =<span class="number">32</span></span><br><span class="line"><span class="keyword">transform</span> = transforms.Compose([transforms.ToTensor(),</span><br><span class="line">                                transforms.Normalize((<span class="number">0.1307</span>),(<span class="number">0.3081</span>))</span><br><span class="line">                                ])</span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(<span class="string">&#x27;&#x27;</span>，train=<span class="keyword">True</span>,download=<span class="keyword">True</span>,</span><br><span class="line">                                <span class="keyword">transform</span> = <span class="keyword">transform</span>)</span><br><span class="line">train_loader = DataLoader(train_dataset,batch_size = batch_size,shuffle = <span class="keyword">True</span>,num_workers=<span class="number">2</span>)</span><br><span class="line">test_dataset = datasets.MNIST(<span class="string">&#x27;&#x27;</span>，train=<span class="keyword">False</span>,download=<span class="keyword">True</span>,</span><br><span class="line">                                <span class="keyword">transform</span> = <span class="keyword">transform</span>)</span><br><span class="line">test_loader = DataLoader(test_dataset,batch_size = batch_size,shuffle = <span class="keyword">True</span>,num_workers=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<ol>
<li>导入包</li>
</ol>
<p>torchvision: 计算机视觉工具包<br>&amp;emsp; .transforms:常见图像预处理方法<br>&amp;emsp; .datasets:常见数据集dataset实现，eg.MNIST,CIFAR,ImageNet<br>&amp;emsp; .model:常见模型训练，eg.AlexNet,VGG,ResNet  </p>
<p>transforms:  </p>
<figure class="highlight clean"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models,transforms</span><br><span class="line">#迁移学习，预处理模型</span><br><span class="line">net = models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">#数据转换</span><br><span class="line">image_transform = transforms.Compose([</span><br><span class="line">    #将输入图片resize成统一尺寸</span><br><span class="line">    transforms.Resize([<span class="number">224</span>,<span class="number">224</span>]),</span><br><span class="line"></span><br><span class="line">    #将PIL Image或numpy.ndarray转换为tensor,将其先由HWC转换为CHW格式，并除<span class="number">225</span>归一化到[<span class="number">0</span>,<span class="number">1</span>]之间</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line"></span><br><span class="line">    #标准化处理 --&gt;转换为标准正态分布，使模型更容易收敛</span><br><span class="line">    transforms.Normalize(main=[<span class="number">0.485</span>,<span class="number">0.456</span>,<span class="number">0.406</span>],std=[<span class="number">0.229</span>,<span class="number">0.224</span>,<span class="number">0.225</span>])</span><br><span class="line">    ])</span><br></pre></td></tr></table></figure>

<p>&amp;emsp; transforms.ToTensor()后，数据分布在[0,1]之间，可能实际bias(b)输入会比较大，模型初始化时b&#x3D;0，神经网络收敛较慢，经Normalize后，可加快模型收敛速度<br><a href="https://www.cxyzjd.com/article/qq_38765642/109779370">数据归一化处理transforms.Normalize（）</a><br>导入数据集：<br>trianset:train &#x3D; True; testset: train &#x3D; False<br><code>xxxset = torchvision.datasets.xxx(&#39;&#39;,train = xxx, download=True,transform = xxx)</code><br>加载数据集:<br>dataset:数据来源，batch_size:每批进入多少数据，一般为2的幂次方，shuffle &#x3D; True –&gt;打乱数据顺序<br>num_workers: (<a href="https://blog.csdn.net/qq_24407657/article/details/103992170">pytorch中num_workers详解</a>)<br><code>xxxloader = DataLoader(dataset,batch_size = batch_size, shuffle = True, num_workers = )</code>  </p>
<h3 id="Step-2-定义神经网络"><a href="#Step-2-定义神经网络" class="headerlink" title="Step 2.定义神经网络"></a>Step 2.定义神经网络</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># MNIST:1*28*28</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net,self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>,<span class="number">10</span>,kernel_size = <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">10</span>,<span class="number">20</span>,kernel_size = <span class="number">5</span>)</span><br><span class="line">        self.pooling = nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">320</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        batch_size = x.size(<span class="number">0</span>)</span><br><span class="line">        x = F.relu(self.pooling(self.conv1(x))) </span><br><span class="line">		   <span class="comment">#10*24*24&gt;&gt;10*12*12</span></span><br><span class="line">		   </span><br><span class="line">        x = F.relu(self.pooling(self.conv2(x)))</span><br><span class="line">		   <span class="comment">#20*8*8&gt;&gt;20*4*4</span></span><br><span class="line">		   </span><br><span class="line">        x = x.view(batch_size,-<span class="number">1</span>)</span><br><span class="line">        x = self.fc1(x) <span class="comment"># 20*4*4 &gt;&gt; 10</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"></span><br><span class="line">```  </span><br><span class="line"><span class="comment">##### 尺寸大小计算</span></span><br><span class="line">```mathjax!</span><br><span class="line">$$</span><br><span class="line">Output = \frac&#123;Input+2Padding-Kernel&#125;&#123;Stride&#125;+ <span class="number">1</span></span><br><span class="line">$$</span><br></pre></td></tr></table></figure>
<p>kernel_size: 5x5, 3x3 可以直接写成 kernel_size &#x3D; 5; 3<br>如果是3x5这种，kernel_size &#x3D; (3,5)<br>padding：填充（上下填充）eg, padding &#x3D; 1, 32x32 &gt;&gt; 34x34<br>所以，如果想要不改变尺寸大小，一般来说<br>kernel_size &#x3D; 3 &gt;&gt; padding &#x3D; 1<br>kernel_size &#x3D; 5 &gt;&gt; padding &#x3D; 2</p>
<p>MaxPool2d(): <a href="https://blog.csdn.net/weixin_38481963/article/details/109962715">torch.nn.MaxPool2d详解</a><br>&amp;emsp; 通道数(C不变)，H,W按照尺寸大小计算，简单的情况下，比如MaxPool2d(2) &#x3D; MaxPool2d(2,2), 直接H,W除2</p>
<p>Linear(): 全连接，尺寸数计算直接CHW相乘</p>
<h3 id="Step-3-定义损失函数和优化器"><a href="#Step-3-定义损失函数和优化器" class="headerlink" title="Step 3. 定义损失函数和优化器"></a>Step 3. 定义损失函数和优化器</h3><figure class="highlight reasonml"><table><tr><td class="code"><pre><span class="line">import torch.optim <span class="keyword">as</span> optim</span><br><span class="line">criterion = nn.<span class="constructor">CrossEntropyLoss()</span></span><br><span class="line">optimizer = optim.<span class="constructor">Adam(<span class="params">net</span>.<span class="params">parameters</span>()</span>,lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>
<p>3.1  <a href="https://blog.csdn.net/qq_25105061/article/details/107381316">CrossEntropyLoss 与 NLLLoss区别与联系</a><br>对于CrossEntropyLoss：网络最后一层线性层输出<strong>可以直接作为该损失函数的输入</strong><br>对于NLLLoss: 网络最后一层<strong>不可以直接作为输入</strong>，要额外加一层.logsoftmax()</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">For <span class="symbol">CrossEntropyLoss:</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Mole):</span><br><span class="line">.......</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"><span class="variable language_">self</span>,x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.Linear(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">For <span class="symbol">NLLLoss:</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Mole):</span><br><span class="line">.......</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"><span class="variable language_">self</span>,x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.Linear(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.loftmax(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line"></span><br><span class="line">criterion = nn.NLLLoss()</span><br></pre></td></tr></table></figure>
<p>3.2 optim.Adam(): <a href="https://blog.csdn.net/KGzhang/article/details/77479737">torch.optim优化算法理解之optim.Adam()</a><br>更多优化相关的理解可以参考<a href="https://paddlepedia.readthedocs.io/en/latest/tutorials/deep_learning/optimizers/index.html">深化学习&gt;优化策略</a><br>自己的深度学习基本知识笔记也总结了一些优化算法的基本思路和想法<br>Ref:<a href="https://blog.csdn.net/willduan1/article/details/78070086">深度学习优化算法解析(Momentum, RMSProp, Adam)</a></p>
<h3 id="Step-4-训练和测试"><a href="#Step-4-训练和测试" class="headerlink" title="Step 4. 训练和测试"></a>Step 4. 训练和测试</h3><figure class="highlight css"><table><tr><td class="code"><pre><span class="line">def train(epoch):</span><br><span class="line">    for data in train_loader:</span><br><span class="line">    X, y = data</span><br><span class="line">    optimizer.<span class="built_in">zero_grad</span>()</span><br><span class="line"></span><br><span class="line">    output = <span class="built_in">net</span>(X)</span><br><span class="line">    loss = <span class="built_in">criterion</span>(output,y)</span><br><span class="line">    loss.<span class="built_in">backward</span>()</span><br><span class="line">    optimizer.<span class="built_in">step</span>()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def <span class="built_in">test</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    with torch.<span class="built_in">no_grad</span>():</span><br><span class="line">        for data in test_loader:</span><br><span class="line">        X,y = data</span><br><span class="line">        output = <span class="built_in">net</span>(X)</span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(output.data,dim=<span class="number">1</span>)</span><br><span class="line">        total + = y.<span class="built_in">size</span>(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == y).<span class="built_in">sum</span>().<span class="built_in">item</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy on test set: %.3f %%&#x27;</span> % (<span class="number">100</span>*correct/total))</span><br><span class="line"></span><br><span class="line">EPOCHS = <span class="number">5</span></span><br><span class="line">for epoch in <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    <span class="built_in">train</span>(epoch)</span><br><span class="line">    <span class="built_in">test</span>()</span><br></pre></td></tr></table></figure>
<p><code>optimizer.zero_grad()</code>:梯度重新归零，因为反向传播中梯度会累加上一次循环的梯度<br><code>_,predicted = torch.max(output.data,dim=1)</code>：‘_’表示我们对第一个值不敢兴趣; torch.max:返回输入tensor中每行最大值并转换为指定的dim(dim&#x3D;0返回每列最大值，dim&#x3D;1返回每行最大值)。<code>torch.max(output.data,dim=1)</code>返回一个tuple,第一个元素对应Image data，第二个元素对应label<br>训练常见格式：  </p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="selector-tag">i</span>,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader):</span><br><span class="line">    inputs, labels = data</span><br><span class="line">    optimizer<span class="selector-class">.zero_grad</span>()</span><br><span class="line"></span><br><span class="line">    outputs = <span class="built_in">net</span>(inputs)</span><br><span class="line">    loss = <span class="built_in">criterion</span>(outputs<span class="selector-class">.data</span>, labels)</span><br><span class="line">    loss<span class="selector-class">.backward</span>()</span><br><span class="line">    optimizer<span class="selector-class">.step</span>()</span><br></pre></td></tr></table></figure>
<p>测试常见格式：  </p>
<figure class="highlight stylus"><table><tr><td class="code"><pre><span class="line">with torch<span class="selector-class">.no_grad</span>():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images,labels = data</span><br><span class="line">        outputs = <span class="built_in">net</span>(images)</span><br><span class="line">        _,predicted = torch<span class="selector-class">.max</span>(outputs<span class="selector-class">.data</span>,dim=<span class="number">1</span>)</span><br><span class="line">        total += labels<span class="selector-class">.size</span>(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted==labels)<span class="selector-class">.sum</span>()<span class="selector-class">.item</span>()</span><br><span class="line"><span class="function"><span class="title">print</span><span class="params">(<span class="string">&quot;Accuracy on tests: %.3f%%&quot;</span> % (<span class="number">100</span>*correct/total)</span></span>)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>ML</category>
      </categories>
      <tags>
        <tag>Pytorch</tag>
        <tag>CN</tag>
        <tag>MNIST</tag>
      </tags>
  </entry>
  <entry>
    <title>Node.js Install</title>
    <url>/2022/07/04/Nodejs_install/</url>
    <content><![CDATA[<h2 id="Basic-Step"><a href="#Basic-Step" class="headerlink" title="Basic Step"></a>Basic Step</h2><p>1.First Install from the <a href="https://nodejs.org/en/">Official Website</a><br>2.Install <a href="https://blog.csdn.net/Small_Yogurt/article/details/104968169">Reference Install</a>  </p>
<h2 id="Solve-WARN"><a href="#Solve-WARN" class="headerlink" title="Solve WARN"></a>Solve WARN</h2><p><code>npm WARN config global `--global`, `--local` are deprecated. Use `--location=global` instead </code> </p>
<h5 id="My-initial-version-is-8-11-windows-10"><a href="#My-initial-version-is-8-11-windows-10" class="headerlink" title="My initial version is 8.11, windows 10."></a>My initial version is 8.11, windows 10.</h5><p>A common solution is to edit <code>npm.cmd</code>, change <code>prefix -g</code> to <code>prefix --location=global</code>.<br>However, this doesn’t work well for my version. Because when I test <code>npm install express -g</code>, this problem still exists.<br>The main problem is the version, the new ver has already solved it. So, what we need to do is to update.<br><strong>But</strong>, on windows, you cannot directly input <code>nmp install -g npm</code> on cmd.<br>Below is what I did to solve this. <a href="https://blog.csdn.net/m0_59751822/article/details/125229851?spm=1001.2014.3001.5502">Reference</a>  </p>
<h4 id="Step-1-Complete-the-configuration-of-environment-variables"><a href="#Step-1-Complete-the-configuration-of-environment-variables" class="headerlink" title="Step 1. Complete the configuration of environment variables"></a>Step 1. Complete the configuration of environment variables</h4><ol>
<li>Create two folders<code>node_global</code> and <code>node_cache</code> in your nodejs installation directory, create one folder <code>node_modules</code> under the <code>node_global</code> folder.  </li>
<li>open cmd, do what shown below.</li>
</ol>
<pre><code>npm config set prefix &quot;创建的node_global文件夹所在路径&quot;  
npm config set cache &quot;创建的node_cache文件夹所在路径&quot;  
</code></pre>
<ol start="3">
<li>In Environment Variables<br>3.1 In System Variables<br>Create a new variable named <code>NODE_PATH</code>, the variable value  is the location of the new <code>node_modules</code> you created.<br>3.2 In System Variables<br>Open the variable named  <code>path</code>, add two new address <code>Your nodejs directory\node_global</code> and <code>%NODE_PATH%</code>.<br>3.3 In User Variable<br>Open the variable named  <code>path</code>, change the address like <code>......\Roaming\npm</code> to <code>Your nodejs directory\node_global</code><br>3.4 Save your changes</li>
</ol>
<h4 id="Step-2-Open-the-permission-of-your-node-js-directory"><a href="#Step-2-Open-the-permission-of-your-node-js-directory" class="headerlink" title="Step 2. Open the permission of your node.js  directory."></a>Step 2. Open the permission of your node.js  directory.</h4><h4 id="Step-3-Main-Progress"><a href="#Step-3-Main-Progress" class="headerlink" title="Step 3. Main Progress"></a>Step 3. Main Progress</h4><h5 id="3-1-Operations-on-cmd"><a href="#3-1-Operations-on-cmd" class="headerlink" title="3.1  Operations on cmd"></a>3.1  Operations on cmd</h5><ol>
<li>Type “cmd” in the search box on the desktop taskbar and click “Run as administrator”.</li>
<li>input <code>npm install -g npm-windows-upgrade</code>, you should see the <strong>WARN</strong>.</li>
</ol>
<h5 id="3-2-Operations-on-Windows-PoweShell"><a href="#3-2-Operations-on-Windows-PoweShell" class="headerlink" title="3.2 Operations on Windows PoweShell"></a>3.2 Operations on Windows PoweShell</h5><ol>
<li>Still, “Run as administrator”.</li>
<li>Type <code>set-ExecutionPolicy RemoteSigned</code>, Press enter and the option to change the enforcement policy will be displayed; we type <code>Y</code> and press enter; </li>
<li>Type <code>npm-windows-upgrade</code>;then each version will be displayed, use the arrow keys ↑ ↓ to select, default is the newest version, so just press enter. Wait a few moments and the update will be completed.</li>
</ol>
<h5 id="3-3-Test"><a href="#3-3-Test" class="headerlink" title="3.3 Test"></a>3.3 Test</h5><p>We type <code>npm -v</code> in the command prompt box and we can see that even if we don’t change the npm.cmd file, we won’t get an error</p>
]]></content>
      <categories>
        <category>安装问题</category>
      </categories>
      <tags>
        <tag>node.js</tag>
        <tag>EN</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/07/04/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
</search>
